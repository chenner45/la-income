{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Framework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zy-f/la-income/blob/develop/Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLaJAcnbYH6c",
        "outputId": "b7e4c53d-e675-4091-a200-db6d0500c10d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Drive where you have saved the unzipped\n",
        "# workshop folder, e.g. 'acmlab/workshops/week3'\n",
        "FOLDERNAME = 'acmlab/workshops/project'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/acmlab/workshops/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcDrSI8PTwb5",
        "outputId": "d4cef30a-2dd6-404f-f8df-4dd869f45cd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Oct 31 01:05:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWRwmh5XTwb-"
      },
      "source": [
        "from collections import defaultdict, namedtuple\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(229)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import util\n",
        "import webmercator"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TjSjWuwSe2e"
      },
      "source": [
        "**Part 1:** The first function you should write is `csv_to_data()`. This should take in a filename and returns a dictionary `data` from zipcode to average income."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIPyFe0CTwcB"
      },
      "source": [
        "def csv_to_data(filename):\n",
        "    \"\"\"Takes in a `filename` and returns a dictionary `data` from zipcode to average income.\n",
        "    For a given row, the average income is computed as \n",
        "    \n",
        "    row['A02650'] / row['N1']\"\"\"\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    data = {}\n",
        "    for idx, row in df.iterrows():\n",
        "        data[row['ZIPCODE']] = row['A02650'] / row['N1']\n",
        "    return data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCC_FV33SqIU",
        "outputId": "48941fe8-a248-4b3b-9d52-27574101e8bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "income_data_raw = csv_to_data('16zpallnoagi.csv')\n",
        "print(len(income_data_raw))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4nrYX6sStP9"
      },
      "source": [
        "**Part 2:** you should write the `load_zip_latlon_info` function. This function should:\n",
        "\n",
        "- Take in a filename representing a path to a latitude/longitude data file with the following columns of interest:\n",
        "    - `zip`: the zipcode\n",
        "    - `state`: the state of the zipcode\n",
        "    - `latitude`, `longitude`: the latitude and longitude of the zipcode\n",
        "- Keep only zipcodes that are in our `data` dictionary.\n",
        "- Convert the latitude and longitude to `x, y` values. (The `webmercator.xy(lat, lon, z)` function may be helpful here.)\n",
        "- Create a dictionary from zipcode to `(x, y)` tuples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vF4gS5lTwcE"
      },
      "source": [
        "def load_zip_latlon_info(filename):\n",
        "    \"\"\"Takes in a `filename` and returns a dictionary from zipcode to (x, y).\"\"\"\n",
        "    df = pd.read_csv(filename, sep=';')                     # the datafile is separated by semicolons for some reason\n",
        "    df = df[df['state'] == 'CA']                            # will make your code more efficient to only work on CA\n",
        "    zip_to_latlon = {}\n",
        "    for idx, row in df.iterrows():                          # loop through the rows of the dataframe\n",
        "        x, y = webmercator.xy(row['latitude'], row['longitude'], 14)\n",
        "        if (2794 <= x <= 2839) and (6528 <= y <= 6572):     # only zip codes in the data set\n",
        "             zip_to_latlon[row['zip']] = (x, y)         \n",
        "    return zip_to_latlon"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qc_q2xnS3xg",
        "outputId": "92556f00-6537-43be-c27b-408ab0ee322b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "zip_to_latlon_raw = load_zip_latlon_info('ziplatlon.csv')\n",
        "income_data = dict([kv for kv in income_data_raw.items() if kv[0] in zip_to_latlon_raw])        # Only keep zipcodes in the \n",
        "zip_to_latlon = {zip:zip_to_latlon_raw[zip] for zip in income_data}\n",
        "print(len(income_data))\n",
        "print(len(zip_to_latlon))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "332\n",
            "332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yehp4gZmTwcH",
        "outputId": "680c1bd4-d53c-4b92-b5b4-6f123d9ed4c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(list(d for d in income_data.values()))\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mggtzgvrVAun"
      },
      "source": [
        "**Part 3:** Write a function `euclidean_distance` that takes in two (x, y) tuples and returns the **squared** Euclidean distance between the two points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ULxIBKTwcJ"
      },
      "source": [
        "def euclidean_distance(pt1, pt2):\n",
        "    x_dist = abs(pt2[0] - pt1[0])\n",
        "    y_dist = abs(pt2[1] - pt1[1])\n",
        "    return x_dist ** 2 + y_dist ** 2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdwqy9FaYS-U"
      },
      "source": [
        "**Part 4**: Write the dataset. The comments should be helpful in walking you through it.\n",
        "\n",
        "For more understanding of how a dataset works, please consult the project handout.\n",
        "\n",
        "Our implementation of the dataset takes about 6 minutes to finish running.  There are definitely more efficient ways to do it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ6EbaqyTwcL"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, main_dir, transform, income_data, zip_to_latlon):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        self.zip_to_latlon = zip_to_latlon\n",
        "        self.zip_to_income = income_data\n",
        "\n",
        "        \n",
        "        self.latlons = []\n",
        "        self.total_imgs = []\n",
        "        oceanic = 0\n",
        "\n",
        "        skipped = 0 # remove\n",
        "\n",
        "        # This loops through all the images in the directory.\n",
        "        for filename in tqdm(sorted(os.listdir(main_dir))):             # tqdm lets you get a nice progress bar\n",
        "            # Step 1: if the filename is not a .jpg, continue. \n",
        "\n",
        "            # Step 2: extract the x and y values out of the filename.\n",
        "            # Remember that a filename is of the form: 14_2817_6565.jpg \n",
        "            # where x=2817, y=6565.\n",
        "            \n",
        "            # Step 3: check if the tile is oceanic (i.e. has elevation 0).\n",
        "            # The util.getElevation function takes in a **latitude** and **longitude** and returns an elevation.\n",
        "            # To get a latitude and longitude from a x and y, use `webmercator.latlon(x, y, z=14)`.\n",
        "            # If it is, ignore it.\n",
        "            \n",
        "            # Step 4: Append (x, y) to the self.latlons list.\n",
        "\n",
        "            if filename.endswith('.jpg') == False:\n",
        "                skipped += 1 # remove\n",
        "                continue\n",
        "\n",
        "            coords = filename.strip('.jpg').split('_')\n",
        "            zoom = int(coords[0])\n",
        "            x = int(coords[1])\n",
        "            y = int(coords[2])\n",
        "\n",
        "\n",
        "            latlon = webmercator.latlon(x, y, zoom)\n",
        "            lat = latlon[0]\n",
        "            lon = latlon[1]\n",
        "            elevation = util.getElevation(lat, lon)\n",
        "\n",
        "            if elevation == oceanic:    #\n",
        "                continue\n",
        "\n",
        "            self.latlons.append((x, y))\n",
        "  \n",
        "            image = Image.open('images/' + filename).convert(\"RGB\")\n",
        "            self.total_imgs.append(image)\n",
        "\n",
        "\n",
        "        self.zipcodes = []                                              # a list of zipcodes \n",
        "        self.tile_to_zipcode = {}\n",
        "        # get the list of zip codes we need\n",
        "        for zipcode, (zipcode_x, zipcode_y) in zip_to_latlon.items():   # loops through zipcodes and their x, y coordinates\n",
        "            for x, y in self.latlons:                                   \n",
        "                if self.in_tile((zipcode_x, zipcode_y), (x, y)):        # check if this zipcode is in the tile\n",
        "                    self.zipcodes.append(zipcode)\n",
        "                    self.tile_to_zipcode[(x, y)] = zipcode\n",
        "        \n",
        "        for idx, (x, y) in enumerate(self.latlons):\n",
        "            if (x, y) not in self.tile_to_zipcode:                     # if this tile isn't already assigned\n",
        "                # find the closest zipcode\n",
        "                # you can use the `min(self.zipcodes, key=FUNCTION)` here\n",
        "                best_zipcode = min(self.zipcodes, key=lambda k: euclidean_distance((self.zip_to_latlon[k]), (x, y)))           #\n",
        "                self.tile_to_zipcode[(x, y)] = best_zipcode\n",
        "\n",
        "        print(len(self.tile_to_zipcode), \"entries.\")\n",
        "                \n",
        "    def __len__(self):\n",
        "        \"\"\"Return the length of the dataset—how many images there are, total.\"\"\"\n",
        "        return len(self.total_imgs)\n",
        "    \n",
        "    def coordinates(self, zipcode):\n",
        "        \"\"\"Returns the coordinates of the given zipcode.\"\"\"\n",
        "        return self.zip_to_latlon[zipcode]     # \n",
        "    \n",
        "    def in_tile(self, coord, square):\n",
        "        \"\"\"checks whether a given coordinate is in a tile\"\"\"\n",
        "        lat, lon = coord\n",
        "        llat, llon = square\n",
        "        ulat, ulon = llat + 1, llon + 1\n",
        "        return (lat >= llat and lon >= llon and lat <= ulat and lon <= ulon)\n",
        "  \n",
        "    def get_image(self, idx):\n",
        "        \"\"\"Returns the image at this index.\"\"\"\n",
        "        return self.total_imgs[idx]     # \n",
        "\n",
        "    def get_label(self, idx):\n",
        "        \"\"\"Given an index, return the ground truth label for that index.\"\"\"\n",
        "        zipcode = self.tile_to_zipcode[self.latlons[idx]]\n",
        "        return np.float32(self.zip_to_income[zipcode])     #\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Return the image and label at a given index\"\"\"\n",
        "        tensor_image =  self.transform(self.get_image(idx))  # \n",
        "        label = self.get_label(idx) # \n",
        "        return tensor_image, label\n",
        "    \n",
        "    def display(self, idx):\n",
        "        \"\"\"Displays the image at a given index\"\"\"\n",
        "        display(self.get_image(idx))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "S3jEPxQsTwcN",
        "outputId": "ab14a6cb-1730-4d74-ede8-7d2511ab2b0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "transform = ToTensor()\n",
        "dset = ImageDataset('images', transform, income_data, zip_to_latlon)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1980/1980 [00:03<00:00, 584.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1457 entries.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_aHM-BGYqZk"
      },
      "source": [
        "This code block creates train and validation dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plXeEHp_TwcQ"
      },
      "source": [
        "validation_split = 0.10\n",
        "dataset_size = len(dset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GSLWfEJTwcS"
      },
      "source": [
        "train_dataloader = DataLoader(dset, batch_size=16, sampler=train_sampler)\n",
        "valid_dataloader = DataLoader(dset, batch_size=16, sampler=valid_sampler)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T3CbPwKYvLN"
      },
      "source": [
        "**Step 5**: Create the model.  Workshop 3 may be useful for this.\n",
        "We suggest a series of convolutional layers interspersed with `torch.nn.MaxPool2d` layers, followed by a series of linear layers.\n",
        "Each convolutional and linear layer should be followed by an activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4GlbxJjiBT6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBNRelu6(nn.Sequential):\n",
        "    def __init__(self, in_, out, kernel, stride, padding=0, groups=1):\n",
        "        super(ConvBNRelu6, self).__init__(\n",
        "            nn.Conv2d(in_channels=in_, out_channels=out, kernel_size=kernel, stride=stride, padding=padding, groups=groups, bias=False),\n",
        "            nn.BatchNorm2d(num_features=out),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "class BottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_channels=128, c=1, t=1, s=1):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        tk = int(round(in_channels*t))\n",
        "        self.use_res = (s==1) and (in_channels==c)\n",
        "        layers = []\n",
        "        if t != 1:\n",
        "            layers.append(ConvBNRelu6(in_=in_channels, out=tk, kernel=(1,1), stride=(1,1)))\n",
        "        layers += [\n",
        "            ConvBNRelu6(in_=tk, out=tk, kernel=(3,3), stride=(s,s), padding=(1,1), groups=tk), #depthwise\n",
        "            nn.Conv2d(in_channels=tk, out_channels=c, kernel_size=(1,1)),\n",
        "            nn.BatchNorm2d(c)\n",
        "        ]\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.use_res:\n",
        "            return x + self.conv(x)\n",
        "        return self.conv(x)\n",
        "\n",
        "# for debug\n",
        "class PrintShape(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintShape, self).__init__()\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        return x"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWJ36pTyKKEG"
      },
      "source": [
        "class Sequence(object):\n",
        "  def __init__(self, **kwargs):\n",
        "      for k,v in kwargs.items():\n",
        "          setattr(self,k,v)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKJbEmXlTwcV"
      },
      "source": [
        "# implementing mobilenetv2: https://arxiv.org/pdf/1801.04381.pdf\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, input_dim=256, img_depth=3, sequence_list=[], dropout=.2, fc_hidden_dims=500):\n",
        "        super(Model, self).__init__()\n",
        "        layers = []\n",
        "        inp_size = img_depth\n",
        "        for seq in sequence_list:\n",
        "          for i in range(seq.n):\n",
        "            if i > 0 and seq.s > 1:\n",
        "                seq.s = 1\n",
        "            if seq.op == 'conv2d':\n",
        "                layers.append(ConvBNRelu6(in_=inp_size, out=seq.c, kernel=seq.kernel, stride=seq.s, padding=seq.kernel//2))\n",
        "            elif seq.op == 'bottleneck':\n",
        "                layers.append(BottleneckBlock(in_channels=inp_size, c=seq.c, t=seq.t, s=seq.s))\n",
        "            elif seq.op == 'avgpool':\n",
        "                layers.append(nn.AvgPool2d(input_dim))\n",
        "            inp_size = seq.c\n",
        "            input_dim //= (input_dim if seq.s==-1 else seq.s)\n",
        "        layers.append(nn.Flatten())\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(inp_size, fc_hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(fc_hidden_dims, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.regressor(x)\n",
        "        return x\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DctOln1W5apo",
        "outputId": "4aeffc8e-88ce-48ee-83db-32cb8142a200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# \"unit test\"\n",
        "# ORIGINAL PAPER SETTINGS\n",
        "\"\"\"\n",
        "sequence_list = [\n",
        "    Sequence(op='conv2d', t=None, c=32, n=1, s=2, kernel=3),\n",
        "    Sequence(op='bottleneck', t=1, c=16, n=1, s=1),\n",
        "    Sequence(op='bottleneck', t=6, c=24, n=2, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=32, n=3, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=64, n=4, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=96, n=3, s=1),\n",
        "    Sequence(op='bottleneck', t=6, c=160, n=3, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=320, n=1, s=1),\n",
        "    Sequence(op='conv2d', t=None, c=1280, n=1, s=1, kernel=1),\n",
        "    Sequence(op='avgpool', t=None, c=1280, n=1, s=-1), #input is now just a vertical stack 1x1x1280 -> linear time\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "# for prebuilt model\n",
        "# prebuilt = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
        "# print(prebuilt)\n",
        "\n",
        "sequence_list = [\n",
        "    Sequence(op='conv2d', t=None, c=32, n=1, s=2, kernel=3),\n",
        "    Sequence(op='bottleneck', t=1, c=16, n=1, s=1),\n",
        "    Sequence(op='bottleneck', t=6, c=24, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=24, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=32, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=32, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=64, n=1, s=2),\n",
        "    Sequence(op='conv2d', t=None, c=160, n=1, s=1, kernel=1),\n",
        "    Sequence(op='avgpool', t=None, c=160, n=1, s=-1), #input is now just a vertical stack 1x1x1280 -> linear time\n",
        "]\n",
        "\n",
        "fc_hidden_dims = 100\n",
        "\n",
        "model = Model(input_dim=256, img_depth=3, sequence_list=sequence_list, fc_hidden_dims=fc_hidden_dims).cuda()\n",
        "print(model)\n",
        "# test_batch = torch.rand(8,3,256,256).cuda()\n",
        "# out = model(test_batch)\n",
        "# print(out)\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (features): Sequential(\n",
            "    (0): ConvBNRelu6(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): ConvBNRelu6(\n",
            "      (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (8): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "    (9): Flatten()\n",
            "  )\n",
            "  (regressor): Sequential(\n",
            "    (0): Linear(in_features=160, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Sat Oct 31 01:33:24 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    30W /  70W |   6581MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtDjwL6yaYUJ"
      },
      "source": [
        "**Step 6**: Train the model. Use `torch.nn.MSELoss(reduction='sum')` here, or one of the other losses specified in the project spec, since we're trying to output a real value (not categories). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jF6i0U8TwcX",
        "outputId": "a50c65c7-a30a-4303-e549-d7f45aefcd90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train loop\n",
        "# model = Model(input_dim=256, img_depth=3, sequence_list=sequence_list, fc_hidden_dims=fc_hidden_dims)\n",
        "# model = model.cuda()\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "model.train()\n",
        "num_epochs = 200\n",
        "for epoch_num in range(num_epochs):\n",
        "    avg_train_loss = 0\n",
        "    avg_train_l1 = 0\n",
        "    for i, (img_batch, label) in enumerate(train_dataloader):\n",
        "        img_batch = img_batch.cuda()\n",
        "        label = label.cuda()\n",
        "        \n",
        "        pred = model(img_batch).squeeze()\n",
        "        loss = criterion(pred, label)\n",
        "        # Step 1: feed your predictions into the model, outputting a variable `pred`\n",
        "        # Step 2: calculate the loss w.r.t the predictions and the labels\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 10)\n",
        "        avg_train_loss += loss.item()\n",
        "        avg_train_l1 += torch.abs(pred - label).sum()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss /= len(train_indices)\n",
        "    avg_train_l1 /= len(train_indices)\n",
        "    print(f'Epoch {epoch_num+1} -> Train loss: {avg_train_loss}    Train L1: {avg_train_l1}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        avg_val_loss = 0\n",
        "        avg_val_l1 = 0\n",
        "        for i, (img_batch, label) in enumerate(valid_dataloader):\n",
        "            img_batch = img_batch.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "            pred = model(img_batch).squeeze()\n",
        "            loss = criterion(pred, label)\n",
        "            # Step 1: feed your predictions into the model, outputting a variable `pred`\n",
        "            # Step 2: calculate the loss w.r.t the predictions and the labels\n",
        "\n",
        "\n",
        "            avg_val_loss += loss\n",
        "            avg_val_l1 += torch.abs(pred - label).sum()\n",
        "        avg_val_loss /= len(val_indices)\n",
        "        avg_val_l1 /= len(val_indices)\n",
        "        print(f'Eval -> Loss: {avg_val_loss}    L1: {avg_val_l1}')\n",
        "        \n",
        "    # print(epoch_num, float(avg_train_loss), float(avg_val_loss), float(avg_train_l1), float(avg_val_l1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 -> Train loss: 4818.410241103754    Train L1: 42.77333450317383\n",
            "Eval -> Loss: 4992.8515625    L1: 45.638912200927734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 -> Train loss: 4554.595472382336    Train L1: 39.37619400024414\n",
            "Eval -> Loss: 4877.4716796875    L1: 41.854740142822266\n",
            "Epoch 3 -> Train loss: 3230.451655690263    Train L1: 34.4557991027832\n",
            "Eval -> Loss: 5550.86572265625    L1: 44.017913818359375\n",
            "Epoch 4 -> Train loss: 2277.377546729111    Train L1: 30.159591674804688\n",
            "Eval -> Loss: 6141.96337890625    L1: 44.58848571777344\n",
            "Epoch 5 -> Train loss: 2475.231093988186    Train L1: 29.61995506286621\n",
            "Eval -> Loss: 5576.689453125    L1: 43.66187286376953\n",
            "Epoch 6 -> Train loss: 2096.8837697098893    Train L1: 28.216550827026367\n",
            "Eval -> Loss: 4867.5537109375    L1: 45.43216323852539\n",
            "Epoch 7 -> Train loss: 2461.418784164801    Train L1: 30.5201473236084\n",
            "Eval -> Loss: 5781.47412109375    L1: 45.671512603759766\n",
            "Epoch 8 -> Train loss: 1829.3173474567693    Train L1: 27.547924041748047\n",
            "Eval -> Loss: 5863.00830078125    L1: 44.36265182495117\n",
            "Epoch 9 -> Train loss: 1950.9511409852562    Train L1: 28.50865936279297\n",
            "Eval -> Loss: 5717.4013671875    L1: 47.01788330078125\n",
            "Epoch 10 -> Train loss: 1758.7881324581983    Train L1: 27.42789649963379\n",
            "Eval -> Loss: 5260.21630859375    L1: 42.99793243408203\n",
            "Epoch 11 -> Train loss: 1798.2080372135813    Train L1: 27.33599853515625\n",
            "Eval -> Loss: 5026.34814453125    L1: 41.17006301879883\n",
            "Epoch 12 -> Train loss: 1823.1700145442312    Train L1: 26.978656768798828\n",
            "Eval -> Loss: 4631.74658203125    L1: 41.52031707763672\n",
            "Epoch 13 -> Train loss: 1417.604345182093    Train L1: 25.555967330932617\n",
            "Eval -> Loss: 4493.6318359375    L1: 44.515655517578125\n",
            "Epoch 14 -> Train loss: 1500.338167144031    Train L1: 24.98005485534668\n",
            "Eval -> Loss: 5734.85302734375    L1: 47.815189361572266\n",
            "Epoch 15 -> Train loss: 1606.674469552389    Train L1: 25.71140480041504\n",
            "Eval -> Loss: 5403.69775390625    L1: 41.851402282714844\n",
            "Epoch 16 -> Train loss: 1231.6225565468392    Train L1: 22.623397827148438\n",
            "Eval -> Loss: 5680.341796875    L1: 47.12491989135742\n",
            "Epoch 17 -> Train loss: 1222.3462513249094    Train L1: 23.576736450195312\n",
            "Eval -> Loss: 5627.6201171875    L1: 47.64015197753906\n",
            "Epoch 18 -> Train loss: 1361.8511047363281    Train L1: 24.390565872192383\n",
            "Eval -> Loss: 5146.14404296875    L1: 41.939327239990234\n",
            "Epoch 19 -> Train loss: 1372.0222614567454    Train L1: 22.93303680419922\n",
            "Eval -> Loss: 5689.40478515625    L1: 46.93524169921875\n",
            "Epoch 20 -> Train loss: 1068.4757889538278    Train L1: 22.05415153503418\n",
            "Eval -> Loss: 5390.40966796875    L1: 40.19534683227539\n",
            "Epoch 21 -> Train loss: 1148.3989386209628    Train L1: 22.506826400756836\n",
            "Eval -> Loss: 4490.0224609375    L1: 41.57461929321289\n",
            "Epoch 22 -> Train loss: 988.3968971066358    Train L1: 20.95836067199707\n",
            "Eval -> Loss: 4568.84716796875    L1: 41.206451416015625\n",
            "Epoch 23 -> Train loss: 1012.2050009006407    Train L1: 21.172218322753906\n",
            "Eval -> Loss: 5323.52685546875    L1: 41.664798736572266\n",
            "Epoch 24 -> Train loss: 1022.3943849889243    Train L1: 21.788450241088867\n",
            "Eval -> Loss: 5383.30810546875    L1: 42.53282928466797\n",
            "Epoch 25 -> Train loss: 1126.45994828387    Train L1: 21.860702514648438\n",
            "Eval -> Loss: 4818.88818359375    L1: 42.89898681640625\n",
            "Epoch 26 -> Train loss: 962.6529407036014    Train L1: 20.960052490234375\n",
            "Eval -> Loss: 4409.4111328125    L1: 40.2425537109375\n",
            "Epoch 27 -> Train loss: 832.9384231567383    Train L1: 19.562122344970703\n",
            "Eval -> Loss: 4289.275390625    L1: 38.265377044677734\n",
            "Epoch 28 -> Train loss: 848.7852777620641    Train L1: 19.72518539428711\n",
            "Eval -> Loss: 4644.70947265625    L1: 42.23853302001953\n",
            "Epoch 29 -> Train loss: 1077.2870046103874    Train L1: 21.60740852355957\n",
            "Eval -> Loss: 5329.34814453125    L1: 40.16666030883789\n",
            "Epoch 30 -> Train loss: 940.3574870039777    Train L1: 20.99820899963379\n",
            "Eval -> Loss: 5851.5087890625    L1: 44.582157135009766\n",
            "Epoch 31 -> Train loss: 1259.4484803734756    Train L1: 22.191287994384766\n",
            "Eval -> Loss: 4815.46875    L1: 42.09904098510742\n",
            "Epoch 32 -> Train loss: 974.8956302549781    Train L1: 19.767005920410156\n",
            "Eval -> Loss: 5978.35791015625    L1: 44.628475189208984\n",
            "Epoch 33 -> Train loss: 865.5824477032917    Train L1: 19.557870864868164\n",
            "Eval -> Loss: 5749.01806640625    L1: 40.91558837890625\n",
            "Epoch 34 -> Train loss: 889.3106799241973    Train L1: 19.138822555541992\n",
            "Eval -> Loss: 5518.72314453125    L1: 40.689456939697266\n",
            "Epoch 35 -> Train loss: 725.3794604976002    Train L1: 17.945932388305664\n",
            "Eval -> Loss: 5300.37646484375    L1: 44.6774787902832\n",
            "Epoch 36 -> Train loss: 817.2551619366901    Train L1: 19.14870262145996\n",
            "Eval -> Loss: 5364.90576171875    L1: 42.67349624633789\n",
            "Epoch 37 -> Train loss: 966.440070175543    Train L1: 19.472078323364258\n",
            "Eval -> Loss: 5112.6611328125    L1: 41.377254486083984\n",
            "Epoch 38 -> Train loss: 806.4664286171518    Train L1: 18.01346206665039\n",
            "Eval -> Loss: 5713.5830078125    L1: 42.07137680053711\n",
            "Epoch 39 -> Train loss: 1048.3187061402855    Train L1: 20.229068756103516\n",
            "Eval -> Loss: 5108.18505859375    L1: 42.179931640625\n",
            "Epoch 40 -> Train loss: 673.6122566781393    Train L1: 17.09198760986328\n",
            "Eval -> Loss: 5204.1728515625    L1: 38.77281951904297\n",
            "Epoch 41 -> Train loss: 750.0534639125917    Train L1: 17.536054611206055\n",
            "Eval -> Loss: 5104.345703125    L1: 41.99730682373047\n",
            "Epoch 42 -> Train loss: 850.7184524536133    Train L1: 18.57945442199707\n",
            "Eval -> Loss: 4914.87548828125    L1: 41.943206787109375\n",
            "Epoch 43 -> Train loss: 935.9398543195026    Train L1: 19.00126075744629\n",
            "Eval -> Loss: 4650.4833984375    L1: 40.286869049072266\n",
            "Epoch 44 -> Train loss: 617.5169156702553    Train L1: 17.007625579833984\n",
            "Eval -> Loss: 5122.6923828125    L1: 40.67436218261719\n",
            "Epoch 45 -> Train loss: 603.2275489248881    Train L1: 16.58179473876953\n",
            "Eval -> Loss: 4428.994140625    L1: 38.10283279418945\n",
            "Epoch 46 -> Train loss: 763.764666022324    Train L1: 16.893142700195312\n",
            "Eval -> Loss: 4815.00732421875    L1: 41.29548645019531\n",
            "Epoch 47 -> Train loss: 809.9438858032227    Train L1: 17.8402042388916\n",
            "Eval -> Loss: 5309.8095703125    L1: 40.682411193847656\n",
            "Epoch 48 -> Train loss: 734.4748815210854    Train L1: 17.835115432739258\n",
            "Eval -> Loss: 5498.5634765625    L1: 42.37710952758789\n",
            "Epoch 49 -> Train loss: 719.8068222418065    Train L1: 17.6057071685791\n",
            "Eval -> Loss: 5346.35693359375    L1: 39.56612014770508\n",
            "Epoch 50 -> Train loss: 600.1841207364711    Train L1: 17.08636474609375\n",
            "Eval -> Loss: 5636.8017578125    L1: 42.20501708984375\n",
            "Epoch 51 -> Train loss: 1008.0624250086342    Train L1: 18.480043411254883\n",
            "Eval -> Loss: 5958.24951171875    L1: 43.79774856567383\n",
            "Epoch 52 -> Train loss: 585.7770195937738    Train L1: 16.612003326416016\n",
            "Eval -> Loss: 5755.380859375    L1: 41.639678955078125\n",
            "Epoch 53 -> Train loss: 544.5497585389672    Train L1: 16.167146682739258\n",
            "Eval -> Loss: 5554.68408203125    L1: 41.27984619140625\n",
            "Epoch 54 -> Train loss: 712.6944835011552    Train L1: 16.927974700927734\n",
            "Eval -> Loss: 5330.47802734375    L1: 40.42845153808594\n",
            "Epoch 55 -> Train loss: 654.8525294792362    Train L1: 16.228384017944336\n",
            "Eval -> Loss: 5321.95703125    L1: 40.39128112792969\n",
            "Epoch 56 -> Train loss: 592.2387672982564    Train L1: 16.50376319885254\n",
            "Eval -> Loss: 5666.70361328125    L1: 43.77940368652344\n",
            "Epoch 57 -> Train loss: 548.305206484911    Train L1: 15.718088150024414\n",
            "Eval -> Loss: 5654.4130859375    L1: 44.22665023803711\n",
            "Epoch 58 -> Train loss: 533.0688656132396    Train L1: 14.597628593444824\n",
            "Eval -> Loss: 5299.81396484375    L1: 40.692405700683594\n",
            "Epoch 59 -> Train loss: 720.4168366222847    Train L1: 16.763532638549805\n",
            "Eval -> Loss: 5709.02294921875    L1: 41.92455291748047\n",
            "Epoch 60 -> Train loss: 672.0089204369522    Train L1: 16.175432205200195\n",
            "Eval -> Loss: 5196.466796875    L1: 41.93214416503906\n",
            "Epoch 61 -> Train loss: 564.4467371498666    Train L1: 16.07622718811035\n",
            "Eval -> Loss: 5929.271484375    L1: 43.023170471191406\n",
            "Epoch 62 -> Train loss: 577.2981174748119    Train L1: 15.484065055847168\n",
            "Eval -> Loss: 5427.2421875    L1: 41.54457473754883\n",
            "Epoch 63 -> Train loss: 476.6572909471465    Train L1: 14.49184799194336\n",
            "Eval -> Loss: 5039.85986328125    L1: 42.66669464111328\n",
            "Epoch 64 -> Train loss: 527.5499585779702    Train L1: 14.783787727355957\n",
            "Eval -> Loss: 5556.662109375    L1: 42.21731185913086\n",
            "Epoch 65 -> Train loss: 732.1908430704257    Train L1: 16.3543643951416\n",
            "Eval -> Loss: 4891.7353515625    L1: 43.24203872680664\n",
            "Epoch 66 -> Train loss: 828.5740228048185    Train L1: 15.439440727233887\n",
            "Eval -> Loss: 5301.8896484375    L1: 41.582645416259766\n",
            "Epoch 67 -> Train loss: 530.8794361207543    Train L1: 15.289020538330078\n",
            "Eval -> Loss: 4918.63525390625    L1: 39.98973846435547\n",
            "Epoch 68 -> Train loss: 417.30933342910396    Train L1: 13.962495803833008\n",
            "Eval -> Loss: 5333.998046875    L1: 42.21061325073242\n",
            "Epoch 69 -> Train loss: 458.0157923814727    Train L1: 14.517123222351074\n",
            "Eval -> Loss: 5795.328125    L1: 41.45208740234375\n",
            "Epoch 70 -> Train loss: 565.335846970721    Train L1: 15.128501892089844\n",
            "Eval -> Loss: 5251.27001953125    L1: 40.36667251586914\n",
            "Epoch 71 -> Train loss: 534.2148257464897    Train L1: 15.392866134643555\n",
            "Eval -> Loss: 5011.1923828125    L1: 38.679874420166016\n",
            "Epoch 72 -> Train loss: 551.6381284202017    Train L1: 15.569853782653809\n",
            "Eval -> Loss: 5252.64306640625    L1: 41.868263244628906\n",
            "Epoch 73 -> Train loss: 460.9624813358958    Train L1: 13.950556755065918\n",
            "Eval -> Loss: 5494.1083984375    L1: 43.45408630371094\n",
            "Epoch 74 -> Train loss: 473.18411208362113    Train L1: 14.290406227111816\n",
            "Eval -> Loss: 5469.60595703125    L1: 45.81711196899414\n",
            "Epoch 75 -> Train loss: 510.91398695038583    Train L1: 14.244154930114746\n",
            "Eval -> Loss: 5513.1875    L1: 42.25041961669922\n",
            "Epoch 76 -> Train loss: 477.8552040472263    Train L1: 13.919242858886719\n",
            "Eval -> Loss: 5074.9052734375    L1: 41.76280975341797\n",
            "Epoch 77 -> Train loss: 396.785586380377    Train L1: 13.257176399230957\n",
            "Eval -> Loss: 5261.7099609375    L1: 40.56977844238281\n",
            "Epoch 78 -> Train loss: 428.11297653942574    Train L1: 13.190319061279297\n",
            "Eval -> Loss: 5345.0263671875    L1: 41.131404876708984\n",
            "Epoch 79 -> Train loss: 393.0209305926067    Train L1: 12.650083541870117\n",
            "Eval -> Loss: 5366.72265625    L1: 39.26692199707031\n",
            "Epoch 80 -> Train loss: 422.0150052512564    Train L1: 13.123785972595215\n",
            "Eval -> Loss: 5043.484375    L1: 41.82917022705078\n",
            "Epoch 81 -> Train loss: 417.3089246982481    Train L1: 13.067325592041016\n",
            "Eval -> Loss: 4929.4541015625    L1: 41.257511138916016\n",
            "Epoch 82 -> Train loss: 486.6600818634033    Train L1: 13.000417709350586\n",
            "Eval -> Loss: 5428.20458984375    L1: 40.550567626953125\n",
            "Epoch 83 -> Train loss: 339.41632387114737    Train L1: 11.922125816345215\n",
            "Eval -> Loss: 5371.23486328125    L1: 41.355010986328125\n",
            "Epoch 84 -> Train loss: 357.3063494984697    Train L1: 11.976798057556152\n",
            "Eval -> Loss: 4231.94921875    L1: 38.98049545288086\n",
            "Epoch 85 -> Train loss: 344.9154868707424    Train L1: 12.280303955078125\n",
            "Eval -> Loss: 4676.9404296875    L1: 38.978763580322266\n",
            "Epoch 86 -> Train loss: 284.3749775770234    Train L1: 11.170812606811523\n",
            "Eval -> Loss: 5383.75341796875    L1: 39.5279655456543\n",
            "Epoch 87 -> Train loss: 552.9747724765684    Train L1: 13.623625755310059\n",
            "Eval -> Loss: 5223.6748046875    L1: 39.94424057006836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "973rGkp4TwcZ"
      },
      "source": [
        "for i in [700, 3, 52, 611, 458, 299]:\n",
        "    display(dset.total_imgs[i])\n",
        "    print(dset[i][1])\n",
        "    print(model(dset[i][0].unsqueeze(0).cuda()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}