{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (rdk)",
      "language": "python",
      "name": "rdk"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Framework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zy-f/la-income/blob/develop/Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLaJAcnbYH6c",
        "outputId": "cb6ba7f9-abf2-42db-dbe4-ff3f43101fb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# this mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# enter the foldername in your Drive where you have saved the unzipped\n",
        "# workshop folder, e.g. 'acmlab/workshops/week3'\n",
        "FOLDERNAME = 'acmlab/workshops/project'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/acmlab/workshops/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcDrSI8PTwb5"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWRwmh5XTwb-"
      },
      "source": [
        "from collections import defaultdict, namedtuple\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(229)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import util\n",
        "import webmercator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TjSjWuwSe2e"
      },
      "source": [
        "**Part 1:** The first function you should write is `csv_to_data()`. This should take in a filename and returns a dictionary `data` from zipcode to average income."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIPyFe0CTwcB"
      },
      "source": [
        "def csv_to_data(filename):\n",
        "    \"\"\"Takes in a `filename` and returns a dictionary `data` from zipcode to average income.\n",
        "    For a given row, the average income is computed as \n",
        "    \n",
        "    row['A02650'] / row['N1']\"\"\"\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    data = {}\n",
        "    for idx, row in df.iterrows():\n",
        "        data[row['ZIPCODE']] = row['A02650'] / row['N1']\n",
        "    return data"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCC_FV33SqIU"
      },
      "source": [
        "income_data_raw = csv_to_data('16zpallnoagi.csv')\n",
        "print(len(income_data_raw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4nrYX6sStP9"
      },
      "source": [
        "**Part 2:** you should write the `load_zip_latlon_info` function. This function should:\n",
        "\n",
        "- Take in a filename representing a path to a latitude/longitude data file with the following columns of interest:\n",
        "    - `zip`: the zipcode\n",
        "    - `state`: the state of the zipcode\n",
        "    - `latitude`, `longitude`: the latitude and longitude of the zipcode\n",
        "- Keep only zipcodes that are in our `data` dictionary.\n",
        "- Convert the latitude and longitude to `x, y` values. (The `webmercator.xy(lat, lon, z)` function may be helpful here.)\n",
        "- Create a dictionary from zipcode to `(x, y)` tuples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vF4gS5lTwcE"
      },
      "source": [
        "def load_zip_latlon_info(filename):\n",
        "    \"\"\"Takes in a `filename` and returns a dictionary from zipcode to (x, y).\"\"\"\n",
        "    df = pd.read_csv(filename, sep=';')                     # the datafile is separated by semicolons for some reason\n",
        "    df = df[df['state'] == 'CA']                            # will make your code more efficient to only work on CA\n",
        "    zip_to_latlon = {}\n",
        "    for idx, row in df.iterrows():                          # loop through the rows of the dataframe\n",
        "        x, y = webmercator.xy(row['latitude'], row['longitude'], 14)\n",
        "        if (2794 <= x <= 2839) and (6528 <= y <= 6572):     # only zip codes in the data set\n",
        "             zip_to_latlon[row['zip']] = (x, y)         \n",
        "    return zip_to_latlon"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qc_q2xnS3xg",
        "outputId": "291a5ad2-0466-47b3-e106-4c9e733bc132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "zip_to_latlon_raw = load_zip_latlon_info('ziplatlon.csv')\n",
        "income_data = dict([kv for kv in income_data_raw.items() if kv[0] in zip_to_latlon_raw])        # Only keep zipcodes in the \n",
        "zip_to_latlon = {zip:zip_to_latlon_raw[zip] for zip in income_data}\n",
        "print(len(income_data))\n",
        "print(len(zip_to_latlon))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "332\n",
            "332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yehp4gZmTwcH",
        "outputId": "35c906a9-626f-41a4-afa7-517016b362e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(list(d for d in data.values()))\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mggtzgvrVAun"
      },
      "source": [
        "**Part 3:** Write a function `euclidean_distance` that takes in two (x, y) tuples and returns the **squared** Euclidean distance between the two points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ULxIBKTwcJ"
      },
      "source": [
        "def euclidean_distance(pt1, pt2):\n",
        "    x_dist = abs(pt2[0] - pt1[0])\n",
        "    y_dist = abs(pt2[1] - pt1[1])\n",
        "    return x_dist ** 2 + y_dist ** 2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdwqy9FaYS-U"
      },
      "source": [
        "**Part 4**: Write the dataset. The comments should be helpful in walking you through it.\n",
        "\n",
        "For more understanding of how a dataset works, please consult the project handout.\n",
        "\n",
        "Our implementation of the dataset takes about 6 minutes to finish running.  There are definitely more efficient ways to do it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ6EbaqyTwcL"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, main_dir, transform, income_data, zip_to_latlon):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        self.zip_to_latlon = zip_to_latlon\n",
        "        self.zip_to_income = income_data\n",
        "\n",
        "        \n",
        "        self.latlons = []\n",
        "        self.total_imgs = []\n",
        "        oceanic = 0\n",
        "\n",
        "        skipped = 0 # remove\n",
        "\n",
        "        # This loops through all the images in the directory.\n",
        "        for filename in tqdm(sorted(os.listdir(main_dir))):             # tqdm lets you get a nice progress bar\n",
        "            # Step 1: if the filename is not a .jpg, continue. \n",
        "\n",
        "            # Step 2: extract the x and y values out of the filename.\n",
        "            # Remember that a filename is of the form: 14_2817_6565.jpg \n",
        "            # where x=2817, y=6565.\n",
        "            \n",
        "            # Step 3: check if the tile is oceanic (i.e. has elevation 0).\n",
        "            # The util.getElevation function takes in a **latitude** and **longitude** and returns an elevation.\n",
        "            # To get a latitude and longitude from a x and y, use `webmercator.latlon(x, y, z=14)`.\n",
        "            # If it is, ignore it.\n",
        "            \n",
        "            # Step 4: Append (x, y) to the self.latlons list.\n",
        "\n",
        "            if filename.endswith('.jpg') == False:\n",
        "                skipped += 1 # remove\n",
        "                continue\n",
        "\n",
        "            coords = filename.strip('.jpg').split('_')\n",
        "            zoom = int(coords[0])\n",
        "            x = int(coords[1])\n",
        "            y = int(coords[2])\n",
        "\n",
        "\n",
        "            latlon = webmercator.latlon(x, y, zoom)\n",
        "            lat = latlon[0]\n",
        "            lon = latlon[1]\n",
        "            elevation = util.getElevation(lat, lon)\n",
        "\n",
        "            if elevation == oceanic:    #\n",
        "                continue\n",
        "\n",
        "            self.latlons.append((x, y))\n",
        "  \n",
        "            image = Image.open('images/' + filename).convert(\"RGB\")\n",
        "            self.total_imgs.append(image)\n",
        "\n",
        "\n",
        "        self.zipcodes = []                                              # a list of zipcodes \n",
        "        self.tile_to_zipcode = {}\n",
        "        # get the list of zip codes we need\n",
        "        for zipcode, (zipcode_x, zipcode_y) in zip_to_latlon.items():   # loops through zipcodes and their x, y coordinates\n",
        "            for x, y in self.latlons:                                   \n",
        "                if self.in_tile((zipcode_x, zipcode_y), (x, y)):        # check if this zipcode is in the tile\n",
        "                    self.zipcodes.append(zipcode)\n",
        "                    self.tile_to_zipcode[(x, y)] = zipcode\n",
        "        \n",
        "        for idx, (x, y) in enumerate(self.latlons):\n",
        "            if (x, y) not in self.tile_to_zipcode:                     # if this tile isn't already assigned\n",
        "                # find the closest zipcode\n",
        "                # you can use the `min(self.zipcodes, key=FUNCTION)` here\n",
        "                best_zipcode = min(self.zipcodes, key=lambda k: euclidean_distance((self.zip_to_latlon[k]), (x, y)))           #\n",
        "                self.tile_to_zipcode[(x, y)] = best_zipcode\n",
        "\n",
        "        print(len(self.tile_to_zipcode), \"entries.\")\n",
        "                \n",
        "    def __len__(self):\n",
        "        \"\"\"Return the length of the dataset—how many images there are, total.\"\"\"\n",
        "        return len(self.total_imgs)\n",
        "    \n",
        "    def coordinates(self, zipcode):\n",
        "        \"\"\"Returns the coordinates of the given zipcode.\"\"\"\n",
        "        return self.zip_to_latlon[zipcode]     # \n",
        "    \n",
        "    def in_tile(self, coord, square):\n",
        "        \"\"\"checks whether a given coordinate is in a tile\"\"\"\n",
        "        lat, lon = coord\n",
        "        llat, llon = square\n",
        "        ulat, ulon = llat + 1, llon + 1\n",
        "        return (lat >= llat and lon >= llon and lat <= ulat and lon <= ulon)\n",
        "  \n",
        "    def get_image(self, idx):\n",
        "        \"\"\"Returns the image at this index.\"\"\"\n",
        "        return self.total_imgs[idx]     # \n",
        "\n",
        "    def get_label(self, idx):\n",
        "        \"\"\"Given an index, return the ground truth label for that index.\"\"\"\n",
        "        zipcode = self.tile_to_zipcode[self.latlons[idx]]\n",
        "        return self.zip_to_income[zipcode]     #\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Return the image and label at a given index\"\"\"\n",
        "        tensor_image =  self.transform(self.get_image(idx))  # \n",
        "        label = self.get_label(idx) # \n",
        "        return tensor_image, label\n",
        "    \n",
        "    def display(self, idx):\n",
        "        \"\"\"Displays the image at a given index\"\"\"\n",
        "        display(self.get_image(idx))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "S3jEPxQsTwcN",
        "outputId": "5bf85ad1-d1d2-4466-e24a-2b1645368363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dset = ImageDataset('images', ToTensor(), income_data, zip_to_latlon)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1980/1980 [00:03<00:00, 650.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1457 entries.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_aHM-BGYqZk"
      },
      "source": [
        "This code block creates train and validation dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plXeEHp_TwcQ"
      },
      "source": [
        "validation_split = 0.10\n",
        "dataset_size = len(dset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GSLWfEJTwcS"
      },
      "source": [
        "train_dataloader = DataLoader(dset, batch_size=32, sampler=train_sampler)\n",
        "valid_dataloader = DataLoader(dset, batch_size=32, sampler=valid_sampler)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T3CbPwKYvLN"
      },
      "source": [
        "**Step 5**: Create the model.  Workshop 3 may be useful for this.\n",
        "We suggest a series of convolutional layers interspersed with `torch.nn.MaxPool2d` layers, followed by a series of linear layers.\n",
        "Each convolutional and linear layer should be followed by an activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4GlbxJjiBT6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBNRelu6(nn.Sequential):\n",
        "    def __init__(self, in_, out, kernel, stride, padding=0, groups=1):\n",
        "        super(ConvBNRelu6, self).__init__(\n",
        "            nn.Conv2d(in_channels=in_, out_channels=out, kernel_size=kernel, stride=stride, padding=padding, groups=groups, bias=False),\n",
        "            nn.BatchNorm2d(num_features=out),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "class BottleneckBlock(nn.Module):\n",
        "    def __init__(self, in_channels=128, c=1, t=1, s=1):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        tk = int(round(in_channels*t))\n",
        "        self.use_res = (s==1) and (in_channels==c)\n",
        "        layers = []\n",
        "        if t != 1:\n",
        "            layers.append(ConvBNRelu6(in_=in_channels, out=tk, kernel=(1,1), stride=(1,1)))\n",
        "        layers += [\n",
        "            ConvBNRelu6(in_=tk, out=tk, kernel=(3,3), stride=(s,s), padding=(1,1), groups=tk), #depthwise\n",
        "            nn.Conv2d(in_channels=tk, out_channels=c, kernel_size=(1,1)),\n",
        "            nn.BatchNorm2d(c)\n",
        "        ]\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.use_res:\n",
        "            return x + self.conv(x)\n",
        "        return self.conv(x)\n",
        "\n",
        "# for debug\n",
        "class PrintShape(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrintShape, self).__init__()\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        return x"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWJ36pTyKKEG"
      },
      "source": [
        "class Sequence(object):\n",
        "  def __init__(self, **kwargs):\n",
        "      for k,v in kwargs.items():\n",
        "          setattr(self,k,v)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKJbEmXlTwcV"
      },
      "source": [
        "# implementing mobilenetv2: https://arxiv.org/pdf/1801.04381.pdf\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, input_dim=256, img_depth=3, sequence_list=[], dropout=.2, fc_hidden_dims=500):\n",
        "        super(Model, self).__init__()\n",
        "        layers = []\n",
        "        inp_size = img_depth\n",
        "        for seq in sequence_list:\n",
        "          for i in range(seq.n):\n",
        "            if i > 0 and seq.s > 1:\n",
        "                seq.s = 1\n",
        "            if seq.op == 'conv2d':\n",
        "                layers.append(ConvBNRelu6(in_=inp_size, out=seq.c, kernel=seq.kernel, stride=seq.s, padding=seq.kernel//2))\n",
        "            elif seq.op == 'bottleneck':\n",
        "                layers.append(BottleneckBlock(in_channels=inp_size, c=seq.c, t=seq.t, s=seq.s))\n",
        "            elif seq.op == 'avgpool':\n",
        "                layers.append(nn.AvgPool2d(input_dim))\n",
        "            inp_size = seq.c\n",
        "            input_dim //= (input_dim if seq.s==-1 else seq.s)\n",
        "        layers.append(nn.Flatten())\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(inp_size, fc_hidden_dims),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(fc_hidden_dims, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.regressor(x)\n",
        "        return x\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DctOln1W5apo",
        "outputId": "94c8d342-71a0-4742-fc58-a3c500c0452c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# \"unit test\"\n",
        "# ORIGINAL PAPER SETTINGS\n",
        "\"\"\"\n",
        "sequence_list = [\n",
        "    Sequence(op='conv2d', t=None, c=32, n=1, s=2, kernel=3),\n",
        "    Sequence(op='bottleneck', t=1, c=16, n=1, s=1),\n",
        "    Sequence(op='bottleneck', t=6, c=24, n=2, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=32, n=3, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=64, n=4, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=96, n=3, s=1),\n",
        "    Sequence(op='bottleneck', t=6, c=160, n=3, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=320, n=1, s=1),\n",
        "    Sequence(op='conv2d', t=None, c=1280, n=1, s=1, kernel=1),\n",
        "    Sequence(op='avgpool', t=None, c=1280, n=1, s=-1), #input is now just a vertical stack 1x1x1280 -> linear time\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "# for prebuilt model\n",
        "# prebuilt = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
        "# print(prebuilt)\n",
        "\n",
        "sequence_list = [\n",
        "    Sequence(op='conv2d', t=None, c=32, n=1, s=2, kernel=3),\n",
        "    Sequence(op='bottleneck', t=1, c=16, n=1, s=1),\n",
        "    Sequence(op='bottleneck', t=6, c=24, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=24, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=32, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=32, n=1, s=2),\n",
        "    Sequence(op='bottleneck', t=6, c=64, n=1, s=2),\n",
        "    Sequence(op='conv2d', t=None, c=160, n=1, s=1, kernel=1),\n",
        "    Sequence(op='avgpool', t=None, c=160, n=1, s=-1), #input is now just a vertical stack 1x1x1280 -> linear time\n",
        "]\n",
        "\n",
        "fc_hidden_dims = 100\n",
        "\n",
        "model = Model(input_dim=256, img_depth=3, sequence_list=sequence_list, fc_hidden_dims=fc_hidden_dims).cuda()\n",
        "print(model)\n",
        "# test_batch = torch.rand(8,3,256,256).cuda()\n",
        "# out = model(test_batch)\n",
        "# print(out)\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (features): Sequential(\n",
            "    (0): ConvBNRelu6(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (1): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): BottleneckBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): ConvBNRelu6(\n",
            "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (1): ConvBNRelu6(\n",
            "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU6(inplace=True)\n",
            "        )\n",
            "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): ConvBNRelu6(\n",
            "      (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU6(inplace=True)\n",
            "    )\n",
            "    (8): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "    (9): Flatten()\n",
            "  )\n",
            "  (regressor): Sequential(\n",
            "    (0): Linear(in_features=160, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=100, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Sat Oct 31 01:03:05 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W /  70W |  15075MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtDjwL6yaYUJ"
      },
      "source": [
        "**Step 6**: Train the model. Use `torch.nn.MSELoss(reduction='sum')` here, or one of the other losses specified in the project spec, since we're trying to output a real value (not categories). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jF6i0U8TwcX",
        "outputId": "34ffc8d0-ff87-4d73-e115-6788e2bad293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "# train loop\n",
        "# model = Model(input_dim=256, img_depth=3, sequence_list=sequence_list, fc_hidden_dims=fc_hidden_dims)\n",
        "# model = model.cuda()\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "writer = SummaryWriter()\n",
        "\n",
        "model.train()\n",
        "num_epochs = 200\n",
        "for epoch_num in range(num_epochs):\n",
        "    avg_train_loss = 0\n",
        "    avg_train_l1 = 0\n",
        "    for i, (img_batch, label) in enumerate(train_dataloader):\n",
        "        img_batch = img_batch.cuda()\n",
        "        label = label.cuda()\n",
        "        \n",
        "        pred = model(img_batch)\n",
        "        loss = criterion(pred, label)\n",
        "        # Step 1: feed your predictions into the model, outputting a variable `pred`\n",
        "        # Step 2: calculate the loss w.r.t the predictions and the labels\n",
        "\n",
        "        avg_train_loss += loss.detach()\n",
        "        avg_train_l1 += torch.abs(pred - label).sum()\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 10)\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss /= len(train_indices)\n",
        "    avg_train_l1 /= len(train_indices)\n",
        "    print(f'Epoch {epoch_num+1} -> Train loss: {avg_train_loss}    Train L1: {avg_train_l1}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        avg_val_loss = 0\n",
        "        avg_val_l1 = 0\n",
        "        for i, (img_batch, label) in enumerate(valid_dataloader):\n",
        "            img_batch = img_batch.cuda()\n",
        "            label = label.cuda()\n",
        "\n",
        "            pred = model(img_batch)\n",
        "            loss = criterion(pred, label)\n",
        "            # Step 1: feed your predictions into the model, outputting a variable `pred`\n",
        "            # Step 2: calculate the loss w.r.t the predictions and the labels\n",
        "\n",
        "\n",
        "            avg_val_loss += loss\n",
        "            avg_val_l1 += torch.abs(pred - label).sum()\n",
        "        avg_val_loss /= len(val_indices)\n",
        "        avg_val_l1 /= len(val_indices)\n",
        "        print(f'Eval -> Loss: {avg_train_loss}    L1: {avg_train_l1}')\n",
        "        \n",
        "    print(epoch_num, float(avg_train_loss), float(avg_val_loss), float(avg_train_l1), float(avg_val_l1))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-a5827f6e5e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Step 1: feed your predictions into the model, outputting a variable `pred`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-0ea5b5771140>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-3928d6cbca46>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# for debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 14.73 GiB total capacity; 13.67 GiB already allocated; 35.88 MiB free; 13.70 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "973rGkp4TwcZ"
      },
      "source": [
        "for i in [700, 3, 52, 611, 458, 299]:\n",
        "    display(dset.total_imgs[i])\n",
        "    print(dset[i][1])\n",
        "    print(model(dset[i][0].unsqueeze(0).cuda()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}